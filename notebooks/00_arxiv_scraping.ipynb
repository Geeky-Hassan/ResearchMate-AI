{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes the arXiv website for papers in the category \"cs.CV\" (Computer Vision), \"stat.ML\" / \"cs.LG\" (Machine Learning) and \"cs.AI\" (Artificial Intelligence). The papers are then saved in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_BASE = Path.cwd().parent / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the arXiv website"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a list of keywords that we will use to query the arXiv API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_keywords = [\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"self-supervised learning\\\"\",\n",
    "    \"\\\"representation learning\\\"\",\n",
    "    \"\\\"image generation\\\"\",\n",
    "    \"\\\"object detection\\\"\",\n",
    "    \"\\\"transfer learning\\\"\",\n",
    "    \"\\\"transformers\\\"\",\n",
    "    \"\\\"adversarial training\",\n",
    "    \"\\\"generative adversarial networks\\\"\",\n",
    "    \"\\\"model compressions\\\"\",\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"few-shot learning\\\"\",\n",
    "    \"\\\"natural language\\\"\",\n",
    "    \"\\\"graph\\\"\",\n",
    "    \"\\\"colorization\\\"\",\n",
    "    \"\\\"depth estimation\\\"\",\n",
    "    \"\\\"point cloud\\\"\",\n",
    "    \"\\\"structured data\\\"\",\n",
    "    \"\\\"optical flow\\\"\",\n",
    "    \"\\\"reinforcement learning\\\"\",\n",
    "    \"\\\"super resolution\\\"\",\n",
    "    \"\\\"attention\\\"\",\n",
    "    \"\\\"tabular\\\"\",\n",
    "    \"\\\"unsupervised learning\\\"\",\n",
    "    \"\\\"semi-supervised learning\\\"\",\n",
    "    \"\\\"explainable\\\"\",\n",
    "    \"\\\"radiance field\\\"\",\n",
    "    \"\\\"decision tree\\\"\",\n",
    "    \"\\\"time series\\\"\",\n",
    "    \"\\\"molecule\\\"\",\n",
    "    \"\\\"large language models\\\"\",\n",
    "    \"\\\"llms\\\"\",\n",
    "    \"\\\"language models\\\"\",\n",
    "    \"\\\"image classification\\\"\",\n",
    "    \"\\\"document image classification\\\"\",\n",
    "    \"\\\"encoder\\\"\",\n",
    "    \"\\\"decoder\\\"\",\n",
    "    \"\\\"multimodal\\\"\",\n",
    "    \"\\\"multimodal deep learning\\\"\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we define a function that creates a search object using the given query. It sets the maximum number of results for each category to 50 and sorts them by the last updated date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = arxiv.Client(num_retries=20, page_size=500)\n",
    "\n",
    "\n",
    "def query_with_keywords(query) -> tuple:\n",
    "    \"\"\"\n",
    "    Query the arXiv API for research papers based on a specific query and filter results by selected categories.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to be used for fetching research papers from arXiv.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing three lists - terms, titles, and abstracts of the filtered research papers.\n",
    "        \n",
    "            terms (list): A list of lists, where each inner list contains the categories associated with a research paper.\n",
    "            titles (list): A list of titles of the research papers.\n",
    "            abstracts (list): A list of abstracts (summaries) of the research papers.\n",
    "            urls (list): A list of URLs for the papers' detail page on the arXiv website.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a search object with the query and sorting parameters.\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=50,\n",
    "        sort_by=arxiv.SortCriterion.LastUpdatedDate\n",
    "    )\n",
    "    \n",
    "    # Initialize empty lists for terms, titles, abstracts, and urls.\n",
    "    terms = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    urls = []\n",
    "\n",
    "    # For each result in the search...\n",
    "    for res in tqdm(client.results(search), desc=query):\n",
    "        # Check if the primary category of the result is in the specified list.\n",
    "        if res.primary_category in [\"cs.CV\", \"stat.ML\", \"cs.LG\", \"cs.AI\"]:\n",
    "            # If it is, append the result's categories, title, summary, and url to their respective lists.\n",
    "            terms.append(res.categories)\n",
    "            titles.append(res.title)\n",
    "            abstracts.append(res.summary)\n",
    "            urls.append(res.entry_id)\n",
    "\n",
    "    # Return the four lists.\n",
    "    return terms, titles, abstracts, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"image segmentation\": 50it [00:06,  7.62it/s]\n",
      "\"self-supervised learning\": 0it [00:02, ?it/s]\n",
      "\"representation learning\": 50it [00:08,  5.65it/s]\n",
      "\"image generation\": 50it [00:08,  6.01it/s]\n",
      "\"object detection\": 50it [00:08,  5.65it/s]\n",
      "\"transfer learning\": 50it [00:12,  3.85it/s]\n",
      "\"transformers\": 50it [00:12,  4.11it/s]\n",
      "\"adversarial training: 0it [00:02, ?it/s]\n",
      "\"generative adversarial networks\": 50it [00:15,  3.19it/s]\n",
      "\"model compressions\": 50it [00:04, 11.13it/s]\n",
      "\"image segmentation\": 50it [00:04, 10.08it/s]\n",
      "\"few-shot learning\": 0it [00:03, ?it/s]\n",
      "\"natural language\": 50it [00:15,  3.14it/s]\n",
      "\"graph\": 50it [00:26,  1.86it/s]\n",
      "\"colorization\": 50it [01:18,  1.57s/it]\n",
      "\"depth estimation\": 50it [00:50,  1.01s/it]\n",
      "\"point cloud\": 50it [00:12,  4.05it/s]\n",
      "\"structured data\": 50it [00:16,  3.05it/s]\n",
      "\"optical flow\": 50it [00:22,  2.18it/s]\n",
      "\"reinforcement learning\": 50it [00:57,  1.15s/it]\n",
      "\"super resolution\": 50it [00:44,  1.13it/s]\n",
      "\"attention\": 50it [00:20,  2.48it/s]\n",
      "\"tabular\": 50it [00:16,  2.99it/s]\n",
      "\"unsupervised learning\": 50it [00:12,  4.11it/s]\n",
      "\"semi-supervised learning\": 0it [00:02, ?it/s]\n",
      "\"explainable\": 50it [00:11,  4.33it/s]\n",
      "\"radiance field\": 50it [00:13,  3.78it/s]\n",
      "\"decision tree\": 50it [00:12,  4.14it/s]\n",
      "\"time series\": 50it [00:10,  4.60it/s]\n",
      "\"molecule\": 50it [00:12,  3.91it/s]\n",
      "\"large language models\": 50it [00:13,  3.75it/s]\n",
      "\"llms\": 50it [00:17,  2.84it/s]\n",
      "\"language models\": 50it [00:25,  2.00it/s]\n",
      "\"image classification\": 50it [01:14,  1.49s/it]\n",
      "\"document image classification\": 29it [00:10,  2.64it/s]\n",
      "\"encoder\": 50it [00:19,  2.56it/s]\n",
      "\"decoder\": 50it [00:18,  2.65it/s]\n",
      "\"multimodal\": 50it [00:15,  3.16it/s]\n",
      "\"multimodal deep learning\": 50it [00:06,  7.70it/s]\n"
     ]
    }
   ],
   "source": [
    "all_titles = []\n",
    "all_abstracts = []\n",
    "all_terms = []\n",
    "all_urls = []\n",
    "\n",
    "for query in query_keywords:\n",
    "    terms, titles, abstracts, urls = query_with_keywords(query)\n",
    "    all_titles.extend(titles)\n",
    "    all_abstracts.extend(abstracts)\n",
    "    all_terms.extend(terms)\n",
    "    all_urls.extend(urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a pandas.DataFrame object to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data = pd.DataFrame({\n",
    "    'titles': all_titles,\n",
    "    'abstracts': all_abstracts,\n",
    "    'terms': all_terms,\n",
    "    'urls': all_urls\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we export the DataFrame to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data.to_csv(PATH_DATA_BASE / 'data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
